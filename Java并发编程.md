[TOC]



## 多线程

### Java的内存模型（JMM）介绍一下

JMM规定了所有变量都存在主内存(Main Memory)中。
但每个线程都有自己的工作内存(Working Memory)（类比CPU缓存）。

- 读数据：线程必须先把变量从主内存拷贝到自己的工作内存，才能使用。
- 写数据：线程只能改自己工作内存里的副本，改完后再刷回主内存。
- 隔离性：线程A看不到线程B工作内存里的数据，它们只能通过主内存来“传话”。

JMM有三大特点：

- 原子性(Atomicity)
  - 定义：一个操作要么全做，要么全不做，不能被中断。
  - 问题：i++就不是原子的（读-改-写三步）。
  - 保障：synchronized

- 可见性(Visibility)
  - 定义：一个线程改了数据，其他线程能立马看见。
  - 问题：线程A改了flag=true，但还在自己缓存里没刷回去；线程B读主内存，还是false。
  - 保障：volatile,synchronized

- 有序性(Ordering)
  - 定义：程序按照代码写的顺序执行。
  - 问题：编译器和CPU为了优化，会进行指令重排序(Instruction Reordering)。单线程没问题，多线程下可能会乱套（比如单例模式的双重检查锁）。
  - 保障：happens-before原则，使用volatile,synchronized来保障

###  Java多线程是什么？需要注意什么？

是指在一个Java程序中同时运行多个线程，这些线程共享程序的内存空间，但有各自的栈和程序计数器，能同时执行不同的任务。

需要注意线程安全、线程间通信和线程的创建和销毁成本。

### Java里面的线程和操作系统的线程一样吗？

是一样的，Java底层会调用pthread_create 来创建线程，是 1 对 1 的线程模型。

### 使用多线程要注意哪些问题？

原子性、可见性、有序性

### 保证数据的一致性有哪些方案呢？

- **事务管理**：使用数据库事务来确保一组数据库操作要么全部成功提交，要么全部失败回滚。通过ACID（原子性、一致性、隔离性、持久性）属性，数据库事务可以保证数据的一致性。
- **锁机制**：使用锁来实现对共享资源的互斥访问。在 Java 中，可以使用 synchronized 关键字、ReentrantLock 或其他锁机制来控制并发访问，从而避免并发操作导致数据不一致。
- **版本控制**：通过乐观锁的方式，在更新数据时记录数据的版本信息，从而避免同时对同一数据进行修改，进而保证数据的一致性。

### 线程的创建方式有哪些?

- 继承java.lang.Thread类
  - 优点：访问简单，直接使用this
  - 缺点：不能再继承其他类
- 实现Runnable接口
  - 优点：只实现（implements）了这个接口，还可以继承（extends）其他类
  - 缺点：编程稍微复杂，访问必须用Thread.currentThread()方法。
- 实现Callable接口与FutureTask
  - 特点：与Runnable一样，不过有返回值，可以抛出异常，但需要包装进一个FutureTask，因为Thread类的构造器只接受Runnable参数，而FutureTask实现了Runnable接口。
- 线程池
  - 优点：可以重用预先创建的线程，避免了线程创建和销毁的开销。
  - 缺点：增加了程序复杂度，当涉及线程池参数调整和故障排查时，错误的配置会导致死锁、资源耗尽等问题，这些问题的诊断和修复可能较为复杂。

### 如何停止一个线程的运行?

**1. 异常法停止（协作式中断）**

- **调用者线程**：调用 `targetThread.interrupt()`，将目标线程的**中断标志设为true**。
- **目标线程**：在其 `run()` 方法中，**需主动检查** `Thread.interrupted()` 或 `isInterrupted()` 状态。如果发现被中断，可以**选择抛出 `InterruptedException` 或进行其他处理**来结束运行。这是**协作式**的，目标线程掌握控制权。

**2. 在沉睡/阻塞中停止**

- **调用者线程**：在目标线程因调用 `sleep()`、`wait()`、`join()` 等方法而**阻塞时**，调用 `targetThread.interrupt()`。
- **目标线程**：会**立即**收到 `InterruptedException` 异常，从而跳出阻塞状态。这是中断机制最典型、最有效的用途之一。

**3. `stop()` 暴力停止（已废弃）**

- **调用者线程**：调用 `targetThread.stop()`。
- **目标线程**：**无论执行到哪一行代码，都会被强制、立即停止**，并释放所有锁。这会导致对象状态损坏、清理工作无法完成等严重后果，因此**绝对禁止使用**。

**4. 使用return停止（协作式中断的另一种响应）**

- **调用者线程**：同样调用 `targetThread.interrupt()` 设置中断标志。
- **目标线程**：在 `run()` 方法中检查到中断状态后，**选择通过 `return` 语句退出方法**来终止线程。这是一种简单、干净的响应方式。

### 调用 interrupt 是如何让线程抛出异常的?

每个线程都有一个中断状态标志，初始为false。当线程A调用 `threadB.interrupt()` 时，核心是设置threadB的中断状态为true，而threadB如何响应完全取决于它**自身所处的状态和代码逻辑**：

1. **如果threadB正阻塞在如 `sleep()`、`wait()`、`join()` 这类可中断的阻塞方法上**，它会立即被唤醒，同时JVM会**清除其中断状态并抛出 `InterruptedException`**。这是中断机制最直接、最高优先级的响应方式。
2. **如果threadB正在正常运行**，`interrupt()` 仅会设置其中断状态，在该被中断的线程中稍后可通过轮询中断状态来决定是否要停止当前正在执行的任务。



### Java线程的状态有哪些？

| 线程状态      | 解释                                                         |
| ------------- | ------------------------------------------------------------ |
| NEW           | 尚未启动的线程状态，即线程创建，**还未调用start方法**        |
| RUNNABLE      | **就绪状态**（调用start，等待调度）+**正在运行**             |
| BLOCKED       | **等待监视器锁**时，陷入阻塞状态                             |
| WAITING       | 等待状态的线程正在**等待**另一线程执行特定的操作（如notify） |
| TIMED_WAITING | 具有**指定等待时间**的等待状态                               |
| TERMINATED    | 线程完成执行，**终止状态**                                   |

### sleep 和 wait的区别是什么？

- **所属分类的不同**：sleep 是 `Thread` 类的静态方法，可以在任何地方直接通过 `Thread.sleep()` 调用，无需依赖对象实例。wait 是 `Object` 类的实例方法，这意味着必须通过对象实例来调用。
- **锁释放的情况**：`Thread.sleep()` 在调用时，线程会暂停执行指定的时间，但不会释放持有的对象锁。也就是说，在 `sleep` 期间，其他线程无法获得该线程持有的锁。`Object.wait()`：调用该方法时，线程会释放持有的对象锁，进入等待状态，直到其他线程调用相同对象的 `notify()` 或 `notifyAll()` 方法唤醒它
- **使用条件**：sleep 可在任意位置调用，无需事先获取锁。 wait 必须在同步块或同步方法内调用（即线程需持有该对象的锁），否则抛出 `IllegalMonitorStateException`。
- **唤醒机制**：sleep 休眠时间结束后，线程 自动恢复 到就绪状态，等待CPU调度。wait 需要其他线程调用相同对象的 `notify()` 或 `notifyAll()` 方法才能被唤醒。`notify()` 会随机唤醒一个在该对象上等待的线程，而 `notifyAll()` 会唤醒所有在该对象上等待的线程

###  sleep会释放cpu吗？

是的，调用 `Thread.sleep()` 时，线程会释放 CPU，但不会释放持有的锁。

**当线程调用** `sleep()` **后，会主动让出 CPU 时间片**，进入 `TIMED_WAITING` 状态。此时操作系统会触发调度，将 CPU 分配给其他处于就绪状态的线程。这样其他线程（无论是需要同一锁的线程还是不相关线程）便有机会执行。

### blocked和waiting有啥区别

- 触发条件：blocked通常是因为拿不到锁进入的，而waiting的等待另一个线程操作执行完
- 唤醒机制：blocked状态在拿到锁之后会变成Runnable，而Waiting状态需要被通过外部事件显式唤醒，比如这个线程Object.wait()之后，另一个线程用Object.notify()或者Object.notifyAll()方法唤醒。

### notify 和 notifyAll 的区别?

notify：随机唤醒一个线程，由JVM线程调度器决定。

notifyAll：所有线程退出wait状态，开始竞争锁，只有一个可以竞争到锁，由系统调度竞争决定

### notify 选择哪个线程?

依赖于具体实现的JVM。JVM有很多实现，比较流行的就是hotspot，hotspot对notofy()的实现并不是我们以为的随机唤醒,，而是“先进先出”的顺序唤醒。

### Java 中线程之间如何进行通信？ 

Java 线程通信的本质就是让多个线程能够协调干活，核心手段分两类：**共享内存**和**消息传递**。

共享内存是最直接的方式，多个线程读写同一块数据。但光能读写还不够，还得解决三个问题：可见性、原子性、有序性。volatile 关键字能保证可见性，但搞不定复合操作的原子性；synchronized 和 Lock 能同时解决这三个问题，但代价是线程要排队。

消息传递则是通过 wait/notify、Condition、BlockingQueue 这些机制，让线程之间互相打招呼。生产者干完活喊一声"有货了"，消费者听到了就去取；消费者发现没货了就等着，直到生产者通知。

### 线程间通信方式有哪些？

1）wait/notify 机制：通过`wait()`等待，`notify()`、`notifyAll()`唤醒，配合 synchronized 使用，线程调 wait 释放锁进入等待，其他线程调 notify 唤醒它

2）Lock + Condition：通过`await()`等待，`signal()`和`signalAll()`唤醒，ReentrantLock 的 newCondition 可以创建多个等待队列，比 wait/notify 灵活

3）BlockingQueue：生产者消费者模型的首选，put 和 take 方法自带阻塞逻辑

4）volatile：轻量级同步，适合一个线程写、多个线程读的场景

### 如何停止一个线程？

- 线程中断机制：通过`interrupt()`发出中断请求，目标线程在其 `run()` 方法中检查中断状态并响应停止，适用于可中断的阻塞场景
- 线程池管理：使用`Future.cancel(true)` 来中断特定任务，或调用 `shutdown()`/`shutdownNow()` 来关闭整个线程池。
- 自定义停止标志位：用`volatile boolean` 变量作为停止信号，线程轮询此变量以决定是否退出。适用于简单无阻塞的场景
- 资源关闭：某些 I/O 或同步操作（如 `Socket.accept()`、`Lock.lock()`）无法通过中断直接响应。此时需结合资源关闭操作来关闭，比如`stop()` 方法。适用于不可中断的阻塞场景

### Go 的协程和 Java 的线程有啥区别？

- 调度模型：Java线程是内核级线程，创建和切换需要操作系统参与，go协程是用户级线程，把多个协程映射到少量的操作系统线程上执行，创建和切换开销低
- 资源消耗：Java创建线程默认约1MB的固定栈空间，大量线程会导致内存耗尽和显著的上下文开销。go初始栈只有2KB，可动态扩缩容量，可以轻松创建十万甚至百万个协程
- 调度方式：Java线程依赖操作系统内核调度，是抢占式的，线程在阻塞时会挂起，导致系统线程资源被占用。Go的调度器会在协程发生阻塞的时候，比如IO操作或者channel操作时，自动把这个协程挂起，让其他协程继续执行，这种协作式调度就非常高效。

## 并发安全

### juc包下你常用的类？

线程池相关：

- `ThreadPoolExecutor`：最核心的线程池类，用于创建和管理线程池。通过它可以灵活地配置线程池的参数，如核心线程数、最大线程数、任务队列等，以满足不同的并发处理需求。
- `Executors`：线程池工厂类，提供了一系列静态方法来创建不同类型的线程池，如`newFixedThreadPool`（创建固定线程数的线程池）、`newCachedThreadPool`（创建可缓存线程池）、`newSingleThreadExecutor`（创建单线程线程池）等，方便开发者快速创建线程池。

并发集合类：

- `ConcurrentHashMap`：线程安全的哈希映射表，用于在多线程环境下高效地存储和访问键值对。它采用了分段锁等技术，允许多个线程同时访问不同的段，提高了并发性能，在高并发场景下比传统的`Hashtable`性能更好。
- `CopyOnWriteArrayList`：线程安全的列表，在对列表进行修改操作时，会创建一个新的底层数组，将修改操作应用到新数组上，而读操作仍然可以在旧数组上进行，从而实现了读写分离，提高了并发读的性能，适用于读多写少的场景。

同步工具类：

- `CountDownLatch`：允许一个或多个线程等待其他一组线程完成操作后再继续执行。它通过一个计数器来实现，计数器初始化为线程的数量，每个线程完成任务后调用`countDown`方法将计数器减一，当计数器为零时，等待的线程可以继续执行。常用于多个线程完成各自任务后，再进行汇总或下一步操作的场景。
- `CyclicBarrier`：让一组线程互相等待，直到所有线程都到达某个屏障点后，再一起继续执行。与`CountDownLatch`不同的是，`CyclicBarrier`可以重复使用，当所有线程都通过屏障后，计数器会重置，可以再次用于下一轮的等待。适用于多个线程需要协同工作，在某个阶段完成后再一起进入下一个阶段的场景。
- `Semaphore`：信号量，用于控制同时访问某个资源的线程数量。它维护了一个许可计数器，线程在访问资源前需要获取许可，如果有可用许可，则获取成功并将许可计数器减一，否则线程需要等待，直到有其他线程释放许可。常用于控制对有限资源的访问，如数据库连接池、线程池中的线程数量等。

原子类：

- `AtomicInteger`：原子整数类，提供了对整数类型的原子操作，如自增、自减、比较并交换等。通过硬件级别的原子指令来保证操作的原子性和线程安全性，避免了使用锁带来的性能开销，在多线程环境下对整数进行计数、状态标记等操作非常方便。
- `AtomicReference`：原子引用类，用于对对象引用进行原子操作。可以保证在多线程环境下，对对象的更新操作是原子性的，即要么全部成功，要么全部失败，不会出现数据不一致的情况。常用于实现无锁数据结构或需要对对象进行原子更新的场景。

### 怎么保证多线程安全？

在只读场景下，可以用不可变对象保证，有数据需要修改的场景下，用：

- **synchronized关键字**:可以使用`synchronized`关键字来同步代码块或方法，确保同一时刻只有一个线程可以访问这些代码。对象锁是通过`synchronized`关键字锁定对象的监视器（monitor）来实现的。

- **volatile关键字**:`volatile`关键字用于变量，确保所有线程看到的是该变量的最新值，而不是可能存储在本地寄存器中的副本。

- **Lock接口和ReentrantLock类**:`java.util.concurrent.locks.Lock`接口提供了比`synchronized`更强大的锁定机制，`ReentrantLock`是一个实现该接口的例子，提供了更灵活的锁管理和更高的性能。

- **原子类**：Java并发库（`java.util.concurrent.atomic`）提供了原子类，如`AtomicInteger`、`AtomicLong`等，这些类提供了原子操作，可以用于更新基本类型的变量而无需额外的同步。

- **线程局部变量**:`ThreadLocal`类可以为每个线程提供独立的变量副本，这样每个线程都拥有自己的变量，消除了竞争条件。

- **并发集合**:使用`java.util.concurrent`包中的线程安全集合，如`ConcurrentHashMap`、`ConcurrentLinkedQueue`等，这些集合内部已经实现了线程安全的逻辑。
- **JUC工具类**: 使用`java.util.concurrent`包中的一些工具类可以用于控制线程间的同步和协作。例如：`Semaphore`和`CyclicBarrier`等。

### Java中有哪些常用的锁，在什么场景下使用？

**内置锁（synchronized）**

Java语言内置的同步机制，用于方法或代码块。

- **锁升级优化**：JVM为减少开销，会根据竞争情况从**无锁**依次升级为**偏向锁**（单线程重复访问）、**轻量级锁**（短暂自旋等待）和**重量级锁**（真正的操作系统互斥锁）。
- **核心特点**：自动加锁与释放，可重入，使用简便。
- **适用场景**：**大多数并发控制的基础选择**，尤其适合锁竞争不激烈、同步代码块执行快的场景。

 **显式锁（ReentrantLock）**

`java.util.concurrent.locks.ReentrantLock`，需手动调用 `lock()` 和 `unlock()`。

- **高级功能**：相比 `synchronized`，额外提供**可中断锁等待**、**尝试获取锁（带超时）** 和**公平锁模式**。
- **公平性**：公平锁按请求顺序分配，保证公平但可能降低吞吐量；非公平锁允许插队，是默认且通常性能更高的模式。
- **适用场景**：需要 `synchronized` 不具备的**高级特性**时，如避免死锁的尝试锁、需要严格按序执行的公平锁。

**读写锁（ReadWriteLock）**

`ReentrantReadWriteLock` 是其实现，将锁分离为读锁和写锁。

- **核心规则**：**共享读**（多个读线程可并发），**独占写**（写线程独占，且与任何读/写互斥）。
- **适用场景**：**明确的读多写少**场景（如缓存、配置存储），可大幅提升读并发性能。

**乐观锁与悲观锁**

两种并发控制思想，并非具体API。

- **悲观锁**：`synchronized` 和 `ReentrantLock` 都是其实现。**假定高冲突**，访问数据前先加锁。
- **乐观锁**：**假定低冲突**，更新数据时再检查版本（如CAS操作、数据库版本号）。Java中 `AtomicInteger` 等原子类是其典型应用。
- **适用场景**：悲观锁用于**竞争激烈**的场景；乐观锁用于**读多写少、冲突概率低**的场景，能获得更高吞吐。

**自旋锁**

一种锁的**实现策略**，而非特定锁类。

- **核心机制**：线程在请求锁时，若锁被占用，会**循环重试（自旋）** 而非立刻被挂起阻塞。
- **权衡**：在**锁持有时间极短**的场景下，自旋比线程挂起/唤醒的代价更小；但自旋过长会空耗CPU。
- **应用**：`synchronized` 轻量级锁阶段、`AtomicInteger` 的CAS操作底层均利用了自旋思想。

### 怎么在实践中用锁的？

核心思想：**能不锁就不锁，非要锁就锁得越短越好**。

1）缩小锁的粒度和持有时间

把锁的范围收到最小，只在真正需要同步的那几行代码上加锁。

2）读写分离

读多写少的场景用 ReentrantReadWriteLock，读锁可以共享，10 个线程同时读没问题，只有写的时候才独占。比如配置缓存，99% 是读操作，用读写锁性能比 synchronized 高一个量级。

3）干脆别用锁

CAS 和原子类能搞定就不用锁。AtomicInteger 的 incrementAndGet 底层就是一条 CPU 的 cmpxchg 指令，没有线程挂起和唤醒的开销，QPS 能从几万飙到几十万。

### Java 并发工具你知道哪些？

Java 并发工具类主要分布在 java.util.concurrent 包下，按功能可以分成这么几类：

1）线程安全的集合类：ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentLinkedQueue

2）原子操作类：AtomicInteger、AtomicLong、AtomicReference、LongAdder 

3）同步协调工具：CountDownLatch、CyclicBarrier、Semaphore、Phaser 

4）阻塞队列：ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue 

5）锁相关：ReentrantLock、ReentrantReadWriteLock、StampedLock

- **ConcurrentHashMap**：最常用的并发集合。JDK 7 用分段锁，把整个 Map 切成 16 个 Segment，每个 Segment 单独加锁；JDK 8 改成了 **CAS + synchronized**，锁粒度细化到单个桶，并发度大幅提升。

- AtomicInteger 和 LongAdder：AtomicInteger 底层靠 CAS 实现，适合低竞争场景。但高并发下 CAS 会频繁失败重试，性能急剧下降。

  JDK 8 引入的 LongAdder 专门解决这个问题。它内部维护一个 base 变量和一个 Cell 数组，不同线程往不同的 Cell 上累加，最后求和。热点分散了，竞争就小了。实测 64 线程并发累加，LongAdder 比 AtomicLong 快 5-10 倍。

- **CountDownLatch**：CountDownLatch 是一个同步辅助类，它允许一个或多个线程等待其他线程完成操作。它使用一个计数器进行初始化，调用 `countDown()` 方法会使计数器减一，当计数器的值减为 0 时，等待的线程会被唤醒。是一次性的，计数器减到 0 就废了，典型场景是主线程等多个子线程完成初始化。
- **CyclicBarrier**：允许一组线程互相等待，直到到达一个公共的屏障点。当所有线程都到达这个屏障点后，它们可以继续执行后续操作，并且这个屏障可以被重置循环使用。适合分阶段并行计算，比如 MapReduce 场景，每轮计算完大家在屏障点汇合，然后进入下一轮
- **Semaphore**：Semaphore 是一个计数信号量，用于控制同时访问某个共享资源的线程数量。通过 `acquire()` 方法获取许可，使用 `release()` 方法释放许可。如果没有许可可用，线程将被阻塞，直到有许可被释放。可以用来限制对某些资源（如数据库连接池、文件操作等）的并发访问量。
- BlockingQueue 生产者消费者：阻塞队列是生产者消费者模型的标配。队列满了 put 阻塞，队列空了 take 阻塞，天然解决了线程协调问题

### CountDownLatch 是做什么的讲一讲？

**用于让一个或多个线程等待其他线程完成操作后再继续执行**。是通过一个计数器（Counter）实现线程间的协调，常用于多线程任务的分阶段控制或主线程等待多个子线程就绪的场景，核心原理：

- **初始化计数器**：创建 `CountDownLatch` 时指定一个初始计数值（如 `N`）。
- **等待线程阻塞**：调用 `await()` 的线程会被阻塞，直到计数器变为 0。
- **任务完成通知**：其他线程完成任务后调用 `countDown()`，使计数器减 1。
- **唤醒等待线程**：当计数器减到 0 时，所有等待的线程会被唤醒。

### synchronized和reentrantlock及其应用场景？

**synchronized**：

- **简单同步需求**： 当你需要对代码块或方法进行简单的同步控制时，`synchronized`是一个很好的选择。它使用起来简单，不需要额外的资源管理，因为锁会在方法退出或代码块执行完毕后自动释放。
- **代码块同步**： 如果你想对特定代码段进行同步，而不是整个方法，可以使用`synchronized`代码块。这可以让你更精细地控制同步的范围，从而减少锁的持有时间，提高并发性能。
- **内置锁的使用**： `synchronized`关键字使用对象的内置锁（也称为监视器锁），这在需要使用对象作为锁对象的情况下很有用，尤其是在对象状态与锁保护的代码紧密相关时。

**ReentrantLock：**

- **高级锁功能需求**： `ReentrantLock`提供了`synchronized`所不具备的高级功能，如公平锁、响应中断、定时锁尝试、以及多个条件变量。当你需要这些功能时，`ReentrantLock`是更好的选择。
- **性能优化**： 在高度竞争的环境中，`ReentrantLock`可以提供比`synchronized`更好的性能，因为它提供了更细粒度的控制，如尝试锁定和定时锁定，可以减少线程阻塞的可能性。
- **复杂同步结构**： 当你需要更复杂的同步结构，如需要多个条件变量来协调线程之间的通信时，`ReentrantLock`及其配套的`Condition`对象可以提供更灵活的解决方案。

### synchronized锁静态方法和普通方法区别？

锁的对象不同：

- **普通方法**：锁的是当前对象实例（`this`）。同一对象实例的 `synchronized` 普通方法，同一时间只能被一个线程访问；不同对象实例间互不影响，可被不同线程同时访问各自的同步普通方法。
- **静态方法**：锁的是当前类的 `Class` 对象。由于类的 `Class` 对象全局唯一，无论多少个对象实例，该静态同步方法同一时间只能被一个线程访问。

### synchronized和reentrantlock区别？

synchronized 和 ReentrantLock 都是 Java 中提供的可重入锁：

- **用法不同**：synchronized 可用来修饰普通方法、静态方法和代码块，而 ReentrantLock 只能用在代码块上。
- **获取锁和释放锁方式不同**：synchronized 会自动加锁和释放锁，当进入 synchronized 修饰的代码块之后会自动加锁，当离开 synchronized 的代码段之后会自动释放锁。而 ReentrantLock 需要手动加锁和释放锁
- **锁类型不同**：synchronized 属于非公平锁，而 ReentrantLock 既可以是公平锁也可以是非公平锁。
- **响应中断不同**：ReentrantLock 可以响应中断，解决死锁的问题，而 synchronized 不能响应中断。
- **底层实现不同**：synchronized 是 JVM 层面通过监视器实现的，而 ReentrantLock 是基于 AQS 实现的。

### 怎么理解可重入锁？

可重入锁是指同一个线程在获取了锁之后，可以再次重复获取该锁而不会造成死锁或其他问题。

ReentrantLock实现可重入锁的机制是基于线程持有锁的计数器。

- 当一个线程第一次获取锁时，计数器会加1，表示该线程持有了锁。在此之后，如果同一个线程再次获取锁，计数器会再次加1。每次线程成功获取锁时，都会将计数器加1。
- 当线程释放锁时，计数器会相应地减1。只有当计数器减到0时，锁才会完全释放，其他线程才有机会获取锁。

### synchronized 支持重入吗？如何实现的?

支持，synchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。

当一个线程请求方法时，会去检查锁状态。

1. 如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。
2. 如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。

在释放锁时，

1. 如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。
2. 如果非可重入锁的，线程退出方法，直接就会释放该锁。

### syncronized锁升级的过程讲一下

具体的锁升级的过程是：**无锁->偏向锁->轻量级锁->重量级锁**。

- **无锁**：这是没有开启偏向锁的时候的状态，在JDK1.6之后偏向锁的默认开启的，但是有一个偏向延迟，需要在JVM启动之后的多少秒之后才能开启，这个可以通过JVM参数进行设置，同时是否开启偏向锁也可以通过JVM参数设置。
- **偏向锁**：如果还没有一个线程拿到这个锁的话，这个状态叫做匿名偏向，当一个线程拿到偏向锁的时候，下次想要竞争锁只需要拿线程ID跟MarkWord当中存储的线程ID进行比较，如果线程ID相同则直接获取锁（相当于锁偏向于这个线程），不需要进行CAS操作和将线程挂起的操作。
- **轻量级锁**：在这个状态下线程主要是通过CAS操作实现的。将对象的MarkWord存储到线程的虚拟机栈上，然后通过CAS将对象的MarkWord的内容设置为指向Displaced Mark Word的指针，如果设置成功则获取锁。在线程出临界区的时候，也需要使用CAS，如果使用CAS替换成功则同步成功，如果失败表示有其他线程在获取锁，那么就需要在释放锁之后将被挂起的线程唤醒。
- **重量级锁**：当有两个以上的线程获取锁的时候轻量级锁就会升级为重量级锁，因为CAS如果没有成功的话始终都在自旋，进行while循环操作，这是非常消耗CPU的，但是在升级为重量级锁之后，线程会被操作系统调度然后挂起，这可以节约CPU资源。

### JVM对Synchornized的优化？

synchronized 核心优化方案主要包含以下 4 个：

- **锁膨胀**：synchronized 从无锁升级到偏向锁，再到轻量级锁，最后到重量级锁的过程，它叫做锁膨胀也叫做锁升级。JDK 1.6 之前，synchronized 是重量级锁，也就是说 synchronized 在释放和获取锁时都会从用户态转换成内核态，而转换的效率是比较低的。但有了锁膨胀机制之后，synchronized 的状态就多了无锁、偏向锁以及轻量级锁了，这时候在进行并发操作时，大部分的场景都不需要用户态到内核态的转换了，这样就大幅的提升了 synchronized 的性能。
- **锁消除**：指的是在某些情况下，JVM 虚拟机如果检测不到某段代码被共享和竞争的可能性，就会将这段代码所属的同步锁消除掉，从而到底提高程序性能的目的。
- **锁粗化**：将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。
- **自适应自旋锁**：指通过自身循环，尝试获取锁的一种方式，优点在于它避免一些线程的挂起和恢复操作，因为挂起线程和恢复线程都需要从用户态转入内核态，这个过程是比较慢的，所以通过自旋的方式可以一定程度上避免线程挂起和恢复所造成的性能开销。

### 介绍一下AQS

AQS全称为AbstractQueuedSynchronizer，是Java中的一个抽象类。 AQS是一个用于构建锁、同步器、协作工具类的工具类（框架）。

AQS最核心的就是三大部分：

- 状态：state；
- 控制线程抢锁和配合的FIFO队列（双向链表）；
- 期望协作工具类去实现的获取/释放等重要方法（重写）。

**状态state**

- 这里state的具体含义，会根据具体实现类的不同而不同：比如在Semapore里，表示剩余许可证的数量；在CountDownLatch里，表示还需要倒数的数量；在ReentrantLock中，state用来表示“锁”的占有情况，包括可重入计数，当state的值为0的时候，标识该Lock不被任何线程所占有。
- state是volatile修饰的，并被并发修改，所以修改state的方法都需要保证线程安全，比如getState、setState以及compareAndSetState操作来读取和更新这个状态。这些方法都依赖于unsafe类。

**FIFO队列**

- 这个队列用来存放“等待的线程，将那些没能拿到锁的线程串在一起。当锁释放时，就会挑选一个合适的线程来占有这个刚刚释放的锁。

**实现获取/释放等方法**

是由协作类自己去实现的，并且含义各不相同：

- 获取方法：获取操作会以来state变量，经常会阻塞（比如获取不到锁的时候）。在Semaphore中，获取就是acquire方法，作用是获取一个许可证； 而在CountDownLatch里面，获取就是await方法，作用是等待，直到倒数结束；
- 释放方法：在Semaphore中，释放就是release方法，作用是释放一个许可证； 在CountDownLatch里面，获取就是countDown方法，作用是将倒数的数减一；
- 需要每个实现类重写tryAcquire和tryRelease等方法。

### CAS 和 AQS 有什么关系？

CAS 和 AQS 两者的区别：

- CAS 是一种乐观锁机制，它包含三个操作数：变量的内存地址、旧的预期值、新值。CPU 根据内存地址拿到变量当前值，和预期值比较，相等就替换成新值，不相等就返回失败。失败了一般会自旋重试，直到成功为止。整个过程是原子性的，通常由硬件指令支持，如在现代处理器上，`cmpxchg` 指令可以实现 CAS 操作。
- AQS 是一个用于构建锁和同步器的框架，许多同步器如 `ReentrantLock`、`Semaphore`、`CountDownLatch` 等都是基于 AQS 构建的。AQS 使用一个 `volatile` 的整数变量 `state` 来表示同步状态，通过内置的 `FIFO` 队列来管理等待线程。它提供了一些基本的操作，如 `acquire`（获取资源）和 `release`（释放资源），这些操作会修改 `state` 的值，并根据 `state` 的值来判断线程是否可以获取或释放资源。AQS 的 `acquire` 操作通常会先尝试获取资源，如果失败，线程将被添加到等待队列中，并阻塞等待。`release` 操作会释放资源，并唤醒等待队列中的线程。

CAS 和 AQS 两者的联系：

- **CAS 为 AQS 提供原子操作支持**：AQS 内部使用 CAS 操作来更新 `state` 变量，以实现线程安全的状态修改。在 `acquire` 操作中，当线程尝试获取资源时，会使用 CAS 操作尝试将 `state` 从一个值更新为另一个值，如果更新失败，说明资源已被占用，线程会进入等待队列。在 `release` 操作中，当线程释放资源时，也会使用 CAS 操作将 `state` 恢复到相应的值，以保证状态更新的原子性。

### 如何用 AQS 实现一个可重入的公平锁？

1. **继承 AbstractQueuedSynchronizer**：创建一个内部类继承自 `AbstractQueuedSynchronizer`，重写 `tryAcquire`、`tryRelease`、`isHeldExclusively` 等方法，这些方法将用于实现锁的获取、释放和判断锁是否被当前线程持有。
2. **实现可重入逻辑**：在 `tryAcquire` 方法中，检查当前线程是否已经持有锁，如果是，则增加锁的持有次数（通过 `state` 变量）；如果不是，尝试使用 CAS操作来获取锁。
3. **实现公平性**：在 `tryAcquire` 方法中，按照队列顺序来获取锁，即先检查等待队列中是否有线程在等待，如果有，当前线程必须进入队列等待，而不是直接竞争锁。
4. **创建锁的外部类**：创建一个外部类，内部持有 `AbstractQueuedSynchronizer` 的子类对象，并提供 `lock` 和 `unlock` 方法，这些方法将调用 `AbstractQueuedSynchronizer` 子类中的方法。

### Threadlocal作用，原理，具体里面存的key value是啥，会有什么问题，如何解决?

`ThreadLocal`是Java中用于解决线程安全问题的一种机制，它允许创建线程局部变量，即每个线程都有自己独立的变量副本，从而避免了线程间的资源共享和同步问题

> ThreadLocal的作用

- **线程隔离**：`ThreadLocal`为每个线程提供了独立的变量副本，这意味着线程之间不会相互影响，可以安全地在多线程环境中使用这些变量而不必担心数据竞争或同步问题。
- **降低耦合度**：在同一个线程内的多个函数或组件之间，使用`ThreadLocal`可以减少参数的传递，降低代码之间的耦合度，使代码更加清晰和模块化。
- **性能优势**：由于`ThreadLocal`避免了线程间的同步开销，所以在大量线程并发执行时，相比传统的锁机制，它可以提供更好的性能。

> ThreadLocal的原理

`ThreadLocal`的实现依赖于`Thread`类中的一个`ThreadLocalMap`字段，这是一个存储`ThreadLocal`变量本身和对应值的映射。每个线程都有自己的`ThreadLocalMap`实例，用于存储该线程所持有的所有`ThreadLocal`变量的值。

当你创建一个`ThreadLocal`变量时，它实际上就是一个`ThreadLocal`对象的实例。每个`ThreadLocal`对象都可以存储任意类型的值，这个值对每个线程来说是独立的。

- 当调用`ThreadLocal`的`get()`方法时，`ThreadLocal`会检查当前线程的`ThreadLocalMap`中是否有与之关联的值。
- 如果有，返回该值；
- 如果没有，会调用`initialValue()`方法（如果重写了的话）来初始化该值，然后将其放入`ThreadLocalMap`中并返回。
- 当调用`set()`方法时，`ThreadLocal`会将给定的值与当前线程关联起来，即在当前线程的`ThreadLocalMap`中存储一个键值对，键是`ThreadLocal`对象自身，值是传入的值。
- 当调用`remove()`方法时，会从当前线程的`ThreadLocalMap`中移除与该`ThreadLocal`对象关联的条目。

> 可能存在的问题

当一个线程结束时，其`ThreadLocalMap`也会随之销毁，但是`ThreadLocal`对象本身不会立即被垃圾回收，直到没有其他引用指向它为止。

因此，在使用`ThreadLocal`时需要注意，**如果不显式调用`remove()`方法，或者线程结束时未正确清理`ThreadLocal`变量，可能会导致内存泄漏，因为`ThreadLocalMap`会持续持有`ThreadLocal`变量的引用，即使这些变量不再被其他地方引用。

### 悲观锁和乐观锁的区别？

- 乐观锁： 对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争发生频率很低，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。
- 悲观锁： 对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像 synchronized，直接上锁操作资源。