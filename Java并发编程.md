[TOC]



## 多线程

### Java的内存模型（JMM）介绍一下

JMM规定了所有变量都存在主内存(Main Memory)中。
但每个线程都有自己的工作内存(Working Memory)（类比CPU缓存）。

- 读数据：线程必须先把变量从主内存拷贝到自己的工作内存，才能使用。
- 写数据：线程只能改自己工作内存里的副本，改完后再刷回主内存。
- 隔离性：线程A看不到线程B工作内存里的数据，它们只能通过主内存来“传话”。

JMM有三大特点：

- 原子性(Atomicity)
  - 定义：一个操作要么全做，要么全不做，不能被中断。
  - 问题：i++就不是原子的（读-改-写三步）。
  - 保障：synchronized

- 可见性(Visibility)
  - 定义：一个线程改了数据，其他线程能立马看见。
  - 问题：线程A改了flag=true，但还在自己缓存里没刷回去；线程B读主内存，还是false。
  - 保障：volatile,synchronized

- 有序性(Ordering)
  - 定义：程序按照代码写的顺序执行。
  - 问题：编译器和CPU为了优化，会进行指令重排序(Instruction Reordering)。单线程没问题，多线程下可能会乱套（比如单例模式的双重检查锁）。
  - 保障：happens-before原则，使用volatile,synchronized来保障

###  Java多线程是什么？需要注意什么？

是指在一个Java程序中同时运行多个线程，这些线程共享程序的内存空间，但有各自的栈和程序计数器，能同时执行不同的任务。

需要注意线程安全、线程间通信和线程的创建和销毁成本。

### Java里面的线程和操作系统的线程一样吗？

是一样的，Java底层会调用pthread_create 来创建线程，是 1 对 1 的线程模型。

### 使用多线程要注意哪些问题？

原子性、可见性、有序性

### 保证数据的一致性有哪些方案呢？

- **事务管理**：使用数据库事务来确保一组数据库操作要么全部成功提交，要么全部失败回滚。通过ACID（原子性、一致性、隔离性、持久性）属性，数据库事务可以保证数据的一致性。
- **锁机制**：使用锁来实现对共享资源的互斥访问。在 Java 中，可以使用 synchronized 关键字、ReentrantLock 或其他锁机制来控制并发访问，从而避免并发操作导致数据不一致。
- **版本控制**：通过乐观锁的方式，在更新数据时记录数据的版本信息，从而避免同时对同一数据进行修改，进而保证数据的一致性。

### 线程的创建方式有哪些?

- 继承java.lang.Thread类
  - 优点：访问简单，直接使用this
  - 缺点：不能再继承其他类
- 实现Runnable接口
  - 优点：只实现（implements）了这个接口，还可以继承（extends）其他类
  - 缺点：编程稍微复杂，访问必须用Thread.currentThread()方法。
- 实现Callable接口与FutureTask
  - 特点：与Runnable一样，不过有返回值，可以抛出异常，但需要包装进一个FutureTask，因为Thread类的构造器只接受Runnable参数，而FutureTask实现了Runnable接口。
- 线程池
  - 优点：可以重用预先创建的线程，避免了线程创建和销毁的开销。
  - 缺点：增加了程序复杂度，当涉及线程池参数调整和故障排查时，错误的配置会导致死锁、资源耗尽等问题，这些问题的诊断和修复可能较为复杂。

### 如何停止一个线程的运行?

**1. 异常法停止（协作式中断）**

- **调用者线程**：调用 `targetThread.interrupt()`，将目标线程的**中断标志设为true**。
- **目标线程**：在其 `run()` 方法中，**需主动检查** `Thread.interrupted()` 或 `isInterrupted()` 状态。如果发现被中断，可以**选择抛出 `InterruptedException` 或进行其他处理**来结束运行。这是**协作式**的，目标线程掌握控制权。

**2. 在沉睡/阻塞中停止**

- **调用者线程**：在目标线程因调用 `sleep()`、`wait()`、`join()` 等方法而**阻塞时**，调用 `targetThread.interrupt()`。
- **目标线程**：会**立即**收到 `InterruptedException` 异常，从而跳出阻塞状态。这是中断机制最典型、最有效的用途之一。

**3. `stop()` 暴力停止（已废弃）**

- **调用者线程**：调用 `targetThread.stop()`。
- **目标线程**：**无论执行到哪一行代码，都会被强制、立即停止**，并释放所有锁。这会导致对象状态损坏、清理工作无法完成等严重后果，因此**绝对禁止使用**。

**4. 使用return停止（协作式中断的另一种响应）**

- **调用者线程**：同样调用 `targetThread.interrupt()` 设置中断标志。
- **目标线程**：在 `run()` 方法中检查到中断状态后，**选择通过 `return` 语句退出方法**来终止线程。这是一种简单、干净的响应方式。

### 调用 interrupt 是如何让线程抛出异常的?

每个线程都有一个中断状态标志，初始为false。当线程A调用 `threadB.interrupt()` 时，核心是设置threadB的中断状态为true，而threadB如何响应完全取决于它**自身所处的状态和代码逻辑**：

1. **如果threadB正阻塞在如 `sleep()`、`wait()`、`join()` 这类可中断的阻塞方法上**，它会立即被唤醒，同时JVM会**清除其中断状态并抛出 `InterruptedException`**。这是中断机制最直接、最高优先级的响应方式。
2. **如果threadB正在正常运行**，`interrupt()` 仅会设置其中断状态，在该被中断的线程中稍后可通过轮询中断状态来决定是否要停止当前正在执行的任务。



### Java线程的状态有哪些？

| 线程状态      | 解释                                                         |
| ------------- | ------------------------------------------------------------ |
| NEW           | 尚未启动的线程状态，即线程创建，**还未调用start方法**        |
| RUNNABLE      | **就绪状态**（调用start，等待调度）+**正在运行**             |
| BLOCKED       | **等待监视器锁**时，陷入阻塞状态                             |
| WAITING       | 等待状态的线程正在**等待**另一线程执行特定的操作（如notify） |
| TIMED_WAITING | 具有**指定等待时间**的等待状态                               |
| TERMINATED    | 线程完成执行，**终止状态**                                   |

### sleep 和 wait的区别是什么？

- **所属分类的不同**：sleep 是 `Thread` 类的静态方法，可以在任何地方直接通过 `Thread.sleep()` 调用，无需依赖对象实例。wait 是 `Object` 类的实例方法，这意味着必须通过对象实例来调用。
- **锁释放的情况**：`Thread.sleep()` 在调用时，线程会暂停执行指定的时间，但不会释放持有的对象锁。也就是说，在 `sleep` 期间，其他线程无法获得该线程持有的锁。`Object.wait()`：调用该方法时，线程会释放持有的对象锁，进入等待状态，直到其他线程调用相同对象的 `notify()` 或 `notifyAll()` 方法唤醒它
- **使用条件**：sleep 可在任意位置调用，无需事先获取锁。 wait 必须在同步块或同步方法内调用（即线程需持有该对象的锁），否则抛出 `IllegalMonitorStateException`。
- **唤醒机制**：sleep 休眠时间结束后，线程 自动恢复 到就绪状态，等待CPU调度。wait 需要其他线程调用相同对象的 `notify()` 或 `notifyAll()` 方法才能被唤醒。`notify()` 会随机唤醒一个在该对象上等待的线程，而 `notifyAll()` 会唤醒所有在该对象上等待的线程

###  sleep会释放cpu吗？

是的，调用 `Thread.sleep()` 时，线程会释放 CPU，但不会释放持有的锁。

**当线程调用** `sleep()` **后，会主动让出 CPU 时间片**，进入 `TIMED_WAITING` 状态。此时操作系统会触发调度，将 CPU 分配给其他处于就绪状态的线程。这样其他线程（无论是需要同一锁的线程还是不相关线程）便有机会执行。

### blocked和waiting有啥区别

- 触发条件：blocked通常是因为拿不到锁进入的，而waiting的等待另一个线程操作执行完
- 唤醒机制：blocked状态在拿到锁之后会变成Runnable，而Waiting状态需要被通过外部事件显式唤醒，比如这个线程Object.wait()之后，另一个线程用Object.notify()或者Object.notifyAll()方法唤醒。

### notify 和 notifyAll 的区别?

notify：随机唤醒一个线程，由JVM线程调度器决定。

notifyAll：所有线程退出wait状态，开始竞争锁，只有一个可以竞争到锁，由系统调度竞争决定

### notify 选择哪个线程?

依赖于具体实现的JVM。JVM有很多实现，比较流行的就是hotspot，hotspot对notofy()的实现并不是我们以为的随机唤醒,，而是“先进先出”的顺序唤醒。

### Java 中线程之间如何进行通信？ 

Java 线程通信的本质就是让多个线程能够协调干活，核心手段分两类：**共享内存**和**消息传递**。

共享内存是最直接的方式，多个线程读写同一块数据。但光能读写还不够，还得解决三个问题：可见性、原子性、有序性。volatile 关键字能保证可见性，但搞不定复合操作的原子性；synchronized 和 Lock 能同时解决这三个问题，但代价是线程要排队。

消息传递则是通过 wait/notify、Condition、BlockingQueue 这些机制，让线程之间互相打招呼。生产者干完活喊一声"有货了"，消费者听到了就去取；消费者发现没货了就等着，直到生产者通知。

### 线程间通信方式有哪些？

1）wait/notify 机制：通过`wait()`等待，`notify()`、`notifyAll()`唤醒，配合 synchronized 使用，线程调 wait 释放锁进入等待，其他线程调 notify 唤醒它

2）Lock + Condition：通过`await()`等待，`signal()`和`signalAll()`唤醒，ReentrantLock 的 newCondition 可以创建多个等待队列，比 wait/notify 灵活

3）BlockingQueue：生产者消费者模型的首选，put 和 take 方法自带阻塞逻辑

4）volatile：轻量级同步，适合一个线程写、多个线程读的场景

### 如何停止一个线程？

- 线程中断机制：通过`interrupt()`发出中断请求，目标线程在其 `run()` 方法中检查中断状态并响应停止，适用于可中断的阻塞场景
- 线程池管理：使用`Future.cancel(true)` 来中断特定任务，或调用 `shutdown()`/`shutdownNow()` 来关闭整个线程池。
- 自定义停止标志位：用`volatile boolean` 变量作为停止信号，线程轮询此变量以决定是否退出。适用于简单无阻塞的场景
- 资源关闭：某些 I/O 或同步操作（如 `Socket.accept()`、`Lock.lock()`）无法通过中断直接响应。此时需结合资源关闭操作来关闭，比如`stop()` 方法。适用于不可中断的阻塞场景

### Go 的协程和 Java 的线程有啥区别？

- 调度模型：Java线程是内核级线程，创建和切换需要操作系统参与，go协程是用户级线程，把多个协程映射到少量的操作系统线程上执行，创建和切换开销低
- 资源消耗：Java创建线程默认约1MB的固定栈空间，大量线程会导致内存耗尽和显著的上下文开销。go初始栈只有2KB，可动态扩缩容量，可以轻松创建十万甚至百万个协程
- 调度方式：Java线程依赖操作系统内核调度，是抢占式的，线程在阻塞时会挂起，导致系统线程资源被占用。Go的调度器会在协程发生阻塞的时候，比如IO操作或者channel操作时，自动把这个协程挂起，让其他协程继续执行，这种协作式调度就非常高效。

## 并发安全

### juc包下你常用的类？

线程池相关：

- `ThreadPoolExecutor`：最核心的线程池类，用于创建和管理线程池。通过它可以灵活地配置线程池的参数，如核心线程数、最大线程数、任务队列等，以满足不同的并发处理需求。
- `Executors`：线程池工厂类，提供了一系列静态方法来创建不同类型的线程池，如`newFixedThreadPool`（创建固定线程数的线程池）、`newCachedThreadPool`（创建可缓存线程池）、`newSingleThreadExecutor`（创建单线程线程池）等，方便开发者快速创建线程池。

并发集合类：

- `ConcurrentHashMap`：线程安全的哈希映射表，用于在多线程环境下高效地存储和访问键值对。它采用了分段锁等技术，允许多个线程同时访问不同的段，提高了并发性能，在高并发场景下比传统的`Hashtable`性能更好。
- `CopyOnWriteArrayList`：线程安全的列表，在对列表进行修改操作时，会创建一个新的底层数组，将修改操作应用到新数组上，而读操作仍然可以在旧数组上进行，从而实现了读写分离，提高了并发读的性能，适用于读多写少的场景。

同步工具类：

- `CountDownLatch`：允许一个或多个线程等待其他一组线程完成操作后再继续执行。它通过一个计数器来实现，计数器初始化为线程的数量，每个线程完成任务后调用`countDown`方法将计数器减一，当计数器为零时，等待的线程可以继续执行。常用于多个线程完成各自任务后，再进行汇总或下一步操作的场景。
- `CyclicBarrier`：让一组线程互相等待，直到所有线程都到达某个屏障点后，再一起继续执行。与`CountDownLatch`不同的是，`CyclicBarrier`可以重复使用，当所有线程都通过屏障后，计数器会重置，可以再次用于下一轮的等待。适用于多个线程需要协同工作，在某个阶段完成后再一起进入下一个阶段的场景。
- `Semaphore`：信号量，用于控制同时访问某个资源的线程数量。它维护了一个许可计数器，线程在访问资源前需要获取许可，如果有可用许可，则获取成功并将许可计数器减一，否则线程需要等待，直到有其他线程释放许可。常用于控制对有限资源的访问，如数据库连接池、线程池中的线程数量等。

原子类：

- `AtomicInteger`：原子整数类，提供了对整数类型的原子操作，如自增、自减、比较并交换等。通过硬件级别的原子指令来保证操作的原子性和线程安全性，避免了使用锁带来的性能开销，在多线程环境下对整数进行计数、状态标记等操作非常方便。
- `AtomicReference`：原子引用类，用于对对象引用进行原子操作。可以保证在多线程环境下，对对象的更新操作是原子性的，即要么全部成功，要么全部失败，不会出现数据不一致的情况。常用于实现无锁数据结构或需要对对象进行原子更新的场景。

### 怎么保证多线程安全？

在只读场景下，可以用不可变对象保证，有数据需要修改的场景下，用：

- **synchronized关键字**:可以使用`synchronized`关键字来同步代码块或方法，确保同一时刻只有一个线程可以访问这些代码。对象锁是通过`synchronized`关键字锁定对象的监视器（monitor）来实现的。

- **volatile关键字**:`volatile`关键字用于变量，确保所有线程看到的是该变量的最新值，而不是可能存储在本地寄存器中的副本。

- **Lock接口和ReentrantLock类**:`java.util.concurrent.locks.Lock`接口提供了比`synchronized`更强大的锁定机制，`ReentrantLock`是一个实现该接口的例子，提供了更灵活的锁管理和更高的性能。

- **原子类**：Java并发库（`java.util.concurrent.atomic`）提供了原子类，如`AtomicInteger`、`AtomicLong`等，这些类提供了原子操作，可以用于更新基本类型的变量而无需额外的同步。

- **线程局部变量**:`ThreadLocal`类可以为每个线程提供独立的变量副本，这样每个线程都拥有自己的变量，消除了竞争条件。

- **并发集合**:使用`java.util.concurrent`包中的线程安全集合，如`ConcurrentHashMap`、`ConcurrentLinkedQueue`等，这些集合内部已经实现了线程安全的逻辑。
- **JUC工具类**: 使用`java.util.concurrent`包中的一些工具类可以用于控制线程间的同步和协作。例如：`Semaphore`和`CyclicBarrier`等。

### Java中有哪些常用的锁，在什么场景下使用？

**内置锁（synchronized）**

Java语言内置的同步机制，用于方法或代码块。

- **锁升级优化**：JVM为减少开销，会根据竞争情况从**无锁**依次升级为**偏向锁**（单线程重复访问）、**轻量级锁**（短暂自旋等待）和**重量级锁**（真正的操作系统互斥锁）。
- **核心特点**：自动加锁与释放，可重入，使用简便。
- **适用场景**：**大多数并发控制的基础选择**，尤其适合锁竞争不激烈、同步代码块执行快的场景。

 **显式锁（ReentrantLock）**

`java.util.concurrent.locks.ReentrantLock`，需手动调用 `lock()` 和 `unlock()`。

- **高级功能**：相比 `synchronized`，额外提供**可中断锁等待**、**尝试获取锁（带超时）** 和**公平锁模式**。
- **公平性**：公平锁按请求顺序分配，保证公平但可能降低吞吐量；非公平锁允许插队，是默认且通常性能更高的模式。
- **适用场景**：需要 `synchronized` 不具备的**高级特性**时，如避免死锁的尝试锁、需要严格按序执行的公平锁。

**读写锁（ReadWriteLock）**

`ReentrantReadWriteLock` 是其实现，将锁分离为读锁和写锁。

- **核心规则**：**共享读**（多个读线程可并发），**独占写**（写线程独占，且与任何读/写互斥）。
- **适用场景**：**明确的读多写少**场景（如缓存、配置存储），可大幅提升读并发性能。

**乐观锁与悲观锁**

两种并发控制思想，并非具体API。

- **悲观锁**：`synchronized` 和 `ReentrantLock` 都是其实现。**假定高冲突**，访问数据前先加锁。
- **乐观锁**：**假定低冲突**，更新数据时再检查版本（如CAS操作、数据库版本号）。Java中 `AtomicInteger` 等原子类是其典型应用。
- **适用场景**：悲观锁用于**竞争激烈**的场景；乐观锁用于**读多写少、冲突概率低**的场景，能获得更高吞吐。

**自旋锁**

一种锁的**实现策略**，而非特定锁类。

- **核心机制**：线程在请求锁时，若锁被占用，会**循环重试（自旋）** 而非立刻被挂起阻塞。
- **权衡**：在**锁持有时间极短**的场景下，自旋比线程挂起/唤醒的代价更小；但自旋过长会空耗CPU。
- **应用**：`synchronized` 轻量级锁阶段、`AtomicInteger` 的CAS操作底层均利用了自旋思想。

### 怎么在实践中用锁的？

核心思想：**能不锁就不锁，非要锁就锁得越短越好**。

1）缩小锁的粒度和持有时间

把锁的范围收到最小，只在真正需要同步的那几行代码上加锁。

2）读写分离

读多写少的场景用 ReentrantReadWriteLock，读锁可以共享，10 个线程同时读没问题，只有写的时候才独占。比如配置缓存，99% 是读操作，用读写锁性能比 synchronized 高一个量级。

3）干脆别用锁

CAS 和原子类能搞定就不用锁。AtomicInteger 的 incrementAndGet 底层就是一条 CPU 的 cmpxchg 指令，没有线程挂起和唤醒的开销，QPS 能从几万飙到几十万。

### Java 并发工具你知道哪些？

Java 并发工具类主要分布在 java.util.concurrent 包下，按功能可以分成这么几类：

1）线程安全的集合类：ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentLinkedQueue

2）原子操作类：AtomicInteger、AtomicLong、AtomicReference、LongAdder 

3）同步协调工具：CountDownLatch、CyclicBarrier、Semaphore、Phaser 

4）阻塞队列：ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue 

5）锁相关：ReentrantLock、ReentrantReadWriteLock、StampedLock

- **ConcurrentHashMap**：最常用的并发集合。JDK 7 用分段锁，把整个 Map 切成 16 个 Segment，每个 Segment 单独加锁；JDK 8 改成了 **CAS + synchronized**，锁粒度细化到单个桶，并发度大幅提升。

- AtomicInteger 和 LongAdder：AtomicInteger 底层靠 CAS 实现，适合低竞争场景。但高并发下 CAS 会频繁失败重试，性能急剧下降。

  JDK 8 引入的 LongAdder 专门解决这个问题。它内部维护一个 base 变量和一个 Cell 数组，不同线程往不同的 Cell 上累加，最后求和。热点分散了，竞争就小了。实测 64 线程并发累加，LongAdder 比 AtomicLong 快 5-10 倍。

- **CountDownLatch**：CountDownLatch 是一个同步辅助类，它允许一个或多个线程等待其他线程完成操作。它使用一个计数器进行初始化，调用 `countDown()` 方法会使计数器减一，当计数器的值减为 0 时，等待的线程会被唤醒。是一次性的，计数器减到 0 就废了，典型场景是主线程等多个子线程完成初始化。
- **CyclicBarrier**：允许一组线程互相等待，直到到达一个公共的屏障点。当所有线程都到达这个屏障点后，它们可以继续执行后续操作，并且这个屏障可以被重置循环使用。适合分阶段并行计算，比如 MapReduce 场景，每轮计算完大家在屏障点汇合，然后进入下一轮
- **Semaphore**：Semaphore 是一个计数信号量，用于控制同时访问某个共享资源的线程数量。通过 `acquire()` 方法获取许可，使用 `release()` 方法释放许可。如果没有许可可用，线程将被阻塞，直到有许可被释放。可以用来限制对某些资源（如数据库连接池、文件操作等）的并发访问量。
- BlockingQueue 生产者消费者：阻塞队列是生产者消费者模型的标配。队列满了 put 阻塞，队列空了 take 阻塞，天然解决了线程协调问题

### CountDownLatch 是做什么的讲一讲？

**用于让一个或多个线程等待其他线程完成操作后再继续执行**。是通过一个计数器（Counter）实现线程间的协调，常用于多线程任务的分阶段控制或主线程等待多个子线程就绪的场景，核心原理：

- **初始化计数器**：创建 `CountDownLatch` 时指定一个初始计数值（如 `N`）。
- **等待线程阻塞**：调用 `await()` 的线程会被阻塞，直到计数器变为 0。
- **任务完成通知**：其他线程完成任务后调用 `countDown()`，使计数器减 1。
- **唤醒等待线程**：当计数器减到 0 时，所有等待的线程会被唤醒。

### synchronized和reentrantlock及其应用场景？

**synchronized**：

- **简单同步需求**： 当你需要对代码块或方法进行简单的同步控制时，`synchronized`是一个很好的选择。它使用起来简单，不需要额外的资源管理，因为锁会在方法退出或代码块执行完毕后自动释放。
- **代码块同步**： 如果你想对特定代码段进行同步，而不是整个方法，可以使用`synchronized`代码块。这可以让你更精细地控制同步的范围，从而减少锁的持有时间，提高并发性能。
- **内置锁的使用**： `synchronized`关键字使用对象的内置锁（也称为监视器锁），这在需要使用对象作为锁对象的情况下很有用，尤其是在对象状态与锁保护的代码紧密相关时。

**ReentrantLock：**

- **高级锁功能需求**： `ReentrantLock`提供了`synchronized`所不具备的高级功能，如公平锁、响应中断、定时锁尝试、以及多个条件变量。当你需要这些功能时，`ReentrantLock`是更好的选择。
- **性能优化**： 在高度竞争的环境中，`ReentrantLock`可以提供比`synchronized`更好的性能，因为它提供了更细粒度的控制，如尝试锁定和定时锁定，可以减少线程阻塞的可能性。
- **复杂同步结构**： 当你需要更复杂的同步结构，如需要多个条件变量来协调线程之间的通信时，`ReentrantLock`及其配套的`Condition`对象可以提供更灵活的解决方案。

### synchronized锁静态方法和普通方法区别？

锁的对象不同：

- **普通方法**：锁的是当前对象实例（`this`）。同一对象实例的 `synchronized` 普通方法，同一时间只能被一个线程访问；不同对象实例间互不影响，可被不同线程同时访问各自的同步普通方法。
- **静态方法**：锁的是当前类的 `Class` 对象。由于类的 `Class` 对象全局唯一，无论多少个对象实例，该静态同步方法同一时间只能被一个线程访问。

### synchronized和reentrantlock区别？

synchronized 和 ReentrantLock 都是 Java 中提供的可重入锁：

- **用法不同**：synchronized 可用来修饰普通方法、静态方法和代码块，而 ReentrantLock 只能用在代码块上。
- **获取锁和释放锁方式不同**：synchronized 会自动加锁和释放锁，当进入 synchronized 修饰的代码块之后会自动加锁，当离开 synchronized 的代码段之后会自动释放锁。而 ReentrantLock 需要手动加锁和释放锁
- **锁类型不同**：synchronized 属于非公平锁，而 ReentrantLock 既可以是公平锁也可以是非公平锁。
- **响应中断不同**：ReentrantLock 可以响应中断，解决死锁的问题，而 synchronized 不能响应中断。
- **底层实现不同**：synchronized 是 JVM 层面通过监视器实现的，而 ReentrantLock 是基于 AQS 实现的。

### 怎么理解可重入锁？

可重入锁是指同一个线程在获取了锁之后，可以再次重复获取该锁而不会造成死锁或其他问题。

ReentrantLock实现可重入锁的机制是基于线程持有锁的计数器。

- 当一个线程第一次获取锁时，计数器会加1，表示该线程持有了锁。在此之后，如果同一个线程再次获取锁，计数器会再次加1。每次线程成功获取锁时，都会将计数器加1。
- 当线程释放锁时，计数器会相应地减1。只有当计数器减到0时，锁才会完全释放，其他线程才有机会获取锁。

### synchronized 支持重入吗？如何实现的?

支持，synchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。

当一个线程请求方法时，会去检查锁状态。

1. 如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。
2. 如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。

在释放锁时，

1. 如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。
2. 如果非可重入锁的，线程退出方法，直接就会释放该锁。

### syncronized锁升级的过程讲一下

具体的锁升级的过程是：**无锁->偏向锁->轻量级锁->重量级锁**。

- **无锁**：这是没有开启偏向锁的时候的状态，在JDK1.6之后偏向锁的默认开启的，但是有一个偏向延迟，需要在JVM启动之后的多少秒之后才能开启，这个可以通过JVM参数进行设置，同时是否开启偏向锁也可以通过JVM参数设置。
- **偏向锁**：如果还没有一个线程拿到这个锁的话，这个状态叫做匿名偏向，当一个线程拿到偏向锁的时候，下次想要竞争锁只需要拿线程ID跟MarkWord当中存储的线程ID进行比较，如果线程ID相同则直接获取锁（相当于锁偏向于这个线程），不需要进行CAS操作和将线程挂起的操作。
- **轻量级锁**：在这个状态下线程主要是通过CAS操作实现的。将对象的MarkWord存储到线程的虚拟机栈上，然后通过CAS将对象的MarkWord的内容设置为指向Displaced Mark Word的指针，如果设置成功则获取锁。在线程出临界区的时候，也需要使用CAS，如果使用CAS替换成功则同步成功，如果失败表示有其他线程在获取锁，那么就需要在释放锁之后将被挂起的线程唤醒。
- **重量级锁**：当有两个以上的线程获取锁的时候轻量级锁就会升级为重量级锁，因为CAS如果没有成功的话始终都在自旋，进行while循环操作，这是非常消耗CPU的，但是在升级为重量级锁之后，线程会被操作系统调度然后挂起，这可以节约CPU资源。

### JVM对Synchornized的优化？

synchronized 核心优化方案主要包含以下 4 个：

- **锁膨胀**：synchronized 从无锁升级到偏向锁，再到轻量级锁，最后到重量级锁的过程，它叫做锁膨胀也叫做锁升级。JDK 1.6 之前，synchronized 是重量级锁，也就是说 synchronized 在释放和获取锁时都会从用户态转换成内核态，而转换的效率是比较低的。但有了锁膨胀机制之后，synchronized 的状态就多了无锁、偏向锁以及轻量级锁了，这时候在进行并发操作时，大部分的场景都不需要用户态到内核态的转换了，这样就大幅的提升了 synchronized 的性能。
- **锁消除**：指的是在某些情况下，JVM 虚拟机如果检测不到某段代码被共享和竞争的可能性，就会将这段代码所属的同步锁消除掉，从而到底提高程序性能的目的。
- **锁粗化**：将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。
- **自适应自旋锁**：指通过自身循环，尝试获取锁的一种方式，优点在于它避免一些线程的挂起和恢复操作，因为挂起线程和恢复线程都需要从用户态转入内核态，这个过程是比较慢的，所以通过自旋的方式可以一定程度上避免线程挂起和恢复所造成的性能开销。

### 介绍一下AQS

AQS全称为AbstractQueuedSynchronizer，是Java中的一个抽象类。 AQS是一个用于构建锁、同步器、协作工具类的工具类（框架）。

AQS最核心的就是三大部分：

- 状态：state；
- 控制线程抢锁和配合的FIFO队列（双向链表）；
- 期望协作工具类去实现的获取/释放等重要方法（重写）。

**状态state**

- 这里state的具体含义，会根据具体实现类的不同而不同：比如在Semapore里，表示剩余许可证的数量；在CountDownLatch里，表示还需要倒数的数量；在ReentrantLock中，state用来表示“锁”的占有情况，包括可重入计数，当state的值为0的时候，标识该Lock不被任何线程所占有。
- state是volatile修饰的，并被并发修改，所以修改state的方法都需要保证线程安全，比如getState、setState以及compareAndSetState操作来读取和更新这个状态。这些方法都依赖于unsafe类。

**FIFO队列**

- 这个队列用来存放“等待的线程，将那些没能拿到锁的线程串在一起。当锁释放时，就会挑选一个合适的线程来占有这个刚刚释放的锁。

**实现获取/释放等方法**

是由协作类自己去实现的，并且含义各不相同：

- 获取方法：获取操作会以来state变量，经常会阻塞（比如获取不到锁的时候）。在Semaphore中，获取就是acquire方法，作用是获取一个许可证； 而在CountDownLatch里面，获取就是await方法，作用是等待，直到倒数结束；
- 释放方法：在Semaphore中，释放就是release方法，作用是释放一个许可证； 在CountDownLatch里面，获取就是countDown方法，作用是将倒数的数减一；
- 需要每个实现类重写tryAcquire和tryRelease等方法。

### CAS 和 AQS 有什么关系？

CAS 和 AQS 两者的区别：

- CAS 是一种乐观锁机制，它包含三个操作数：变量的内存地址、旧的预期值、新值。CPU 根据内存地址拿到变量当前值，和预期值比较，相等就替换成新值，不相等就返回失败。失败了一般会自旋重试，直到成功为止。整个过程是原子性的，通常由硬件指令支持，如在现代处理器上，`cmpxchg` 指令可以实现 CAS 操作。
- AQS 是一个用于构建锁和同步器的框架，许多同步器如 `ReentrantLock`、`Semaphore`、`CountDownLatch` 等都是基于 AQS 构建的。AQS 使用一个 `volatile` 的整数变量 `state` 来表示同步状态，通过内置的 `FIFO` 队列来管理等待线程。它提供了一些基本的操作，如 `acquire`（获取资源）和 `release`（释放资源），这些操作会修改 `state` 的值，并根据 `state` 的值来判断线程是否可以获取或释放资源。AQS 的 `acquire` 操作通常会先尝试获取资源，如果失败，线程将被添加到等待队列中，并阻塞等待。`release` 操作会释放资源，并唤醒等待队列中的线程。

CAS 和 AQS 两者的联系：

- **CAS 为 AQS 提供原子操作支持**：AQS 内部使用 CAS 操作来更新 `state` 变量，以实现线程安全的状态修改。在 `acquire` 操作中，当线程尝试获取资源时，会使用 CAS 操作尝试将 `state` 从一个值更新为另一个值，如果更新失败，说明资源已被占用，线程会进入等待队列。在 `release` 操作中，当线程释放资源时，也会使用 CAS 操作将 `state` 恢复到相应的值，以保证状态更新的原子性。

### 如何用 AQS 实现一个可重入的公平锁？

1. **继承 AbstractQueuedSynchronizer**：创建一个内部类继承自 `AbstractQueuedSynchronizer`，重写 `tryAcquire`、`tryRelease`、`isHeldExclusively` 等方法，这些方法将用于实现锁的获取、释放和判断锁是否被当前线程持有。
2. **实现可重入逻辑**：在 `tryAcquire` 方法中，检查当前线程是否已经持有锁，如果是，则增加锁的持有次数（通过 `state` 变量）；如果不是，尝试使用 CAS操作来获取锁。
3. **实现公平性**：在 `tryAcquire` 方法中，按照队列顺序来获取锁，即先检查等待队列中是否有线程在等待，如果有，当前线程必须进入队列等待，而不是直接竞争锁。
4. **创建锁的外部类**：创建一个外部类，内部持有 `AbstractQueuedSynchronizer` 的子类对象，并提供 `lock` 和 `unlock` 方法，这些方法将调用 `AbstractQueuedSynchronizer` 子类中的方法。

### Threadlocal作用，原理，具体里面存的key value是啥，会有什么问题，如何解决?

`ThreadLocal`是Java中用于解决线程安全问题的一种机制，它允许创建线程局部变量，即每个线程都有自己独立的变量副本，从而避免了线程间的资源共享和同步问题

> ThreadLocal的作用

- **线程隔离**：`ThreadLocal`为每个线程提供了独立的变量副本，这意味着线程之间不会相互影响，可以安全地在多线程环境中使用这些变量而不必担心数据竞争或同步问题。
- **降低耦合度**：在同一个线程内的多个函数或组件之间，使用`ThreadLocal`可以减少参数的传递，降低代码之间的耦合度，使代码更加清晰和模块化。
- **性能优势**：由于`ThreadLocal`避免了线程间的同步开销，所以在大量线程并发执行时，相比传统的锁机制，它可以提供更好的性能。

> ThreadLocal的原理

`ThreadLocal`的实现依赖于`Thread`类中的一个`ThreadLocalMap`字段，这是一个存储`ThreadLocal`变量本身和对应值的映射。每个线程都有自己的`ThreadLocalMap`实例，用于存储该线程所持有的所有`ThreadLocal`变量的值。

当你创建一个`ThreadLocal`变量时，它实际上就是一个`ThreadLocal`对象的实例。每个`ThreadLocal`对象都可以存储任意类型的值，这个值对每个线程来说是独立的。

- 当调用`ThreadLocal`的`get()`方法时，`ThreadLocal`会检查当前线程的`ThreadLocalMap`中是否有与之关联的值。
- 如果有，返回该值；
- 如果没有，会调用`initialValue()`方法（如果重写了的话）来初始化该值，然后将其放入`ThreadLocalMap`中并返回。
- 当调用`set()`方法时，`ThreadLocal`会将给定的值与当前线程关联起来，即在当前线程的`ThreadLocalMap`中存储一个键值对，键是`ThreadLocal`对象自身，值是传入的值。
- 当调用`remove()`方法时，会从当前线程的`ThreadLocalMap`中移除与该`ThreadLocal`对象关联的条目。

> 可能存在的问题

当一个线程结束时，其`ThreadLocalMap`也会随之销毁，但是`ThreadLocal`对象本身不会立即被垃圾回收，直到没有其他引用指向它为止。

因此，在使用`ThreadLocal`时需要注意，**如果不显式调用`remove()`方法，或者线程结束时未正确清理`ThreadLocal`变量，可能会导致内存泄漏，因为`ThreadLocalMap`会持续持有`ThreadLocal`变量的引用，即使这些变量不再被其他地方引用。

### 悲观锁和乐观锁的区别？

- 乐观锁： 对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争发生频率很低，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。
- 悲观锁： 对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像 synchronized，直接上锁操作资源。

### Java中想实现一个乐观锁，都有哪些方式？

1. **CAS（Compare and Swap）操作：** CAS 是乐观锁的基础。Java 提供了 java.util.concurrent.atomic 包，包含各种原子变量类（如 AtomicInteger、AtomicLong），这些类使用 CAS 操作实现了线程安全的原子操作，可以用来实现乐观锁。
2. **版本号控制**：增加一个版本号字段记录数据更新时候的版本，每次更新时递增版本号。在更新数据时，同时比较版本号，若当前版本号和更新前获取的版本号一致，则更新成功，否则失败。
3. **时间戳**：使用时间戳记录数据的更新时间，在更新数据时，在比较时间戳。如果当前时间戳大于数据的时间戳，则说明数据已经被其他线程更新，更新失败。

### CAS 有什么缺点？

CAS的缺点主要有3点：

- **ABA问题**：ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的问题大部分场景下都不影响并发的最终效果。Java中有AtomicStampedReference来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。
- **循环时间长开销大**：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。
- **只能保证一个共享变量的原子操作**：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。

### 为什么不能所有的锁都用CAS？

CAS操作是基于循环重试的机制，如果CAS操作一直未能成功，线程会一直自旋重试，占用CPU资源。在高并发情况下，大量线程自旋会导致CPU资源浪费。

### CAS 有什么问题，Java是怎么解决的？

会有 ABA 的问题，变量值在操作过程中先被其他线程从 **A** 修改为 **B**，又被改回 **A**，CAS 无法感知中途变化，导致操作误判为“未变更”。比如：

- 线程1读取变量为`A`，准备改为`C`。
- 此时线程2将变量`A`→`B`→`A`。
- 线程1的CAS执行时发现仍是`A`，但状态已丢失中间变化。

Java 提供的工具类会在 CAS 操作中增加**版本号（Stamp）或标记**，每次修改都更新版本号，使得即使值相同也能识别变更历史。比如，可以用 AtomicStampedReference 来解决 ABA 问题，通过**比对值和版本号**识别ABA问题。

### voliatle关键字有什么作用？

volatite作用有 2 个：

- **保证变量对所有线程的可见性**。当一个变量被声明为volatile时，它会保证对这个变量的写操作会立即刷新到主存中，而对这个变量的读操作会直接从主存中读取，从而确保了多线程环境下对该变量访问的可见性。这意味着一个线程修改了volatile变量的值，其他线程能够立刻看到这个修改，不会受到各自线程工作内存的影响。
- **禁止指令重排序优化**。volatile关键字在Java中主要通过内存屏障来禁止特定类型的指令重排序。
  - 1）**写-写（Write-Write）屏障**：在对volatile变量执行写操作之前，会插入一个写屏障。这确保了在该变量写操作之前的所有普通写操作都已完成，防止了这些写操作被移到volatile写操作之后。
  - 2）**读-写（Read-Write）屏障**：在对volatile变量执行读操作之后，会插入一个读屏障。它确保了对volatile变量的读操作之后的所有普通读操作都不会被提前到volatile读之前执行，保证了读取到的数据是最新的。
  - 3）**写-读（Write-Read）屏障**：这是最重要的一个屏障，它发生在volatile写之后和volatile读之前。这个屏障确保了volatile写操作之前的所有内存操作（包括写操作）都不会被重排序到volatile读之后，同时也确保了volatile读操作之后的所有内存操作（包括读操作）都不会被重排序到volatile写之前。

### 指令重排序的原理是什么？

在执行程序时，为了提高性能，处理器和编译器常常会对指令进行重排序，但是重排序要满足下面 2 个条件才能进行：

- 在单线程环境下不能改变程序运行的结果
- 存在数据依赖关系的不允许重排序。

所以重排序不会对单线程有影响，只会破坏多线程的执行语义。

### volatile可以保证线程安全吗？

volatile关键字只保证可见性，不能保证原子性，所以不能完全保证线程安全。volatile可以其他线程能够立即看到变量最新的值，避免线程之间的数据不一致。

但volatile并不能解决多线程并发下的复合操作问题，比如i++这种操作不是原子操作，如果多个线程同时对i进行自增操作，volatile不能保证线程安全。对于复合操作，需要使用synchronized关键字或者Lock来保证原子性和线程安全。

### volatile和sychronized比较？

Synchronized保证了同一时刻只允许一个线程访问共享资源，解决了多线程访问共享资源时可能出现的竞态条件和数据不一致的问题，能保证线程安全。Volatile修饰的变量读取不使用缓存，直接从内存中读取，写操作会立即刷回主内存，解决了变量在多线程环境下的可见性和有序性问题，确保了变量的修改对其他线程是可见的，但不能完全保证线程安全。

### 什么是公平锁和非公平锁？

- **公平锁：** 指多个线程按照申请锁的顺序来获取锁。优点在于各个线程公平，每个线程等待一段时间后，都有执行的机会。缺点是整体执行速度更慢，吞吐量更小。
- **非公平锁：** 多个线程加锁时直接尝试获取锁，能抢到锁到直接占有锁，抢不到才会到等待队列的队尾等待。优势在于整体执行速度更快，吞吐量更大。缺点是可能产生线程饥饿问题，如果一直有线程插队，那么在等待队列中的线程可能长时间得不到运行。

### 非公平锁吞吐量为什么比公平锁大？

- **公平锁执行流程**：获取锁时，先将线程自己添加到等待队列的队尾并休眠，当某线程用完锁之后，会去唤醒等待队列中队首的线程尝试去获取锁，在整个过程中，线程会从运行状态切换到休眠状态，再从休眠状态恢复成运行状态，但线程每次休眠和恢复都需要从用户态转换成内核态，而这个状态的转换是比较慢的，所以公平锁的执行速度会比较慢。
- **非公平锁执行流程**：当线程获取锁时，会先通过 CAS 尝试获取锁，如果获取成功就直接拥有锁，如果获取锁失败才会进入等待队列，等待下次尝试获取锁。这样做的好处是，获取锁不用遵循先到先得的规则，从而避免了线程休眠和恢复的操作，这样就加速了程序的执行效率。

### Synchronized是公平锁吗？

Synchronized不属于公平锁，当锁释放时，JVM 会随机唤醒等待队列中的一个线程，被唤醒的线程需要与新到达的线程一起竞争锁。

ReentrantLock是可以选择为公平锁。

### ReentrantLock是怎么实现公平锁的？

公平锁与非公平锁的 lock() 方法唯一的区别就在于公平锁在获取锁时多了一个限制条件：hasQueuedPredecessors() 为 false，这个方法就是判断在等待队列中是否有线程在排队了。如果是公平锁，那么一旦已经有线程在排队了，当前线程就不再尝试获取锁；对于非公平锁而言，无论是否已经有线程在排队，都会尝试获取一下锁，获取不到的话，再去排队。

不过有一个特例，针对 tryLock() 方法，它不遵守设定的公平原则，可以插队。

### 什么情况会产生死锁问题？如何解决？

死锁只有**同时满足**以下四个条件才会发生：

- 互斥条件：指**多个线程不能同时使用同一个资源**。
- 持有并等待条件：当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是**线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1**。
- 不可剥夺条件：当线程已经持有了资源 ，**在自己使用完之前不能被其他线程获取。**
- 环路等待条件：在死锁发生的时候，**两个线程获取资源的顺序构成了环形链**。

解决：

需要破环其中一个条件，最常见的并且可行的就是**使用资源有序分配法，来破环路等待条件**。就是给资源排序，线程必须获取到前一个资源后才能获取后一个资源。

## 线程池

### **线程池怎么使用？**

线程池的核心作用是复用线程、控制并发数，避免频繁创建销毁线程带来的性能开销。

最常用的是通过Executors工具类快速创建线程池，适合简单场景，不用手动配置参数。但 Executors 创建的线程池有潜在问题，比如 newCachedThreadPool 可能创建大量线程导致 OOM，newScheduledThreadPool 的核心线程数默认无界所以复杂业务场景更推荐用 ThreadPoolExecutor 手动配置，能精准控制线程池行为。

### 介绍一下线程池的工作原理

线程池是为了减少频繁的创建线程和销毁线程带来的性能损耗，线程池的工作原理如下图：

![img](https://cdn.xiaolincoding.com//picgo/1719389039034-0de42388-4ec6-44a6-9583-5d018e5cb4f3.png)

### 线程池的参数有哪些？

线程池的构造函数有7个参数：

- **corePoolSize**：线程池核心线程数量。默认情况下，线程池中线程的数量如果 <= corePoolSize，那么即使这些线程处于空闲状态，那也不会被销毁。
- **maximumPoolSize**：限制了线程池能创建的**最大线程总数**（包括核心线程和非核心线程），当 `corePoolSize` 已满 并且 尝试将新任务加入阻塞队列失败（即队列已满）并且 当前线程数 < `maximumPoolSize`，就会创建新线程执行此任务，但是当 `corePoolSize` 满 并且 队列满 并且 线程数已达 `maximumPoolSize` 并且 又有新任务提交时，就会触发拒绝策略。
- **keepAliveTime**：当线程池中线程的数量大于corePoolSize，并且某个线程的空闲时间超过了keepAliveTime，那么这个线程就会被销毁。
- **unit**：就是keepAliveTime时间的单位。
- **workQueue**：工作队列。当没有空闲的线程执行新任务时，该任务就会被放入工作队列中，等待执行。
- **threadFactory**：线程工厂。可以用来给线程取名字等等
- **handler**：拒绝策略。当一个新任务交给线程池，如果此时线程池中有空闲的线程，就会直接执行，如果没有空闲的线程，就会将该任务加入到阻塞队列中，如果阻塞队列满了，就会创建一个新线程，从阻塞队列头部取出一个任务来执行，并将新任务加入到阻塞队列末尾。如果当前线程池中线程的数量等于maximumPoolSize，就不会创建新线程，就会去执行拒绝策略

### 线程池工作队列满了有哪些拒绝策略？

- CallerRunsPolicy，使用线程池的调用者所在的线程去执行被拒绝的任务，除非线程池被停止或者线程池的任务队列已有空缺。
- AbortPolicy，直接抛 RejectedExecutionException，这是默认策略。调用方**能立即感知**任务被拒，适合核心业务场景，比如订单支付必须让上游知道这单没处理。
- DiscardPolicy，静默丢弃，不抛异常也不执行。只适合那些丢了也无所谓的场景，比如埋点上报。
- DiscardOldestPolicy，抛弃排队最久的那个任务，然后把当前任务加进去。
- 自定义拒绝策略，通过实现接口可以自定义任务拒绝策略。

### 有线程池参数设置的经验吗？

核心线程数（corePoolSize）设置的经验：

- CPU密集型：corePoolSize = CPU核数 + 1（避免过多线程竞争CPU）
- IO密集型：corePoolSize = CPU核数 x 2（或更高，具体看IO等待时间）

场景一：电商场景，特点瞬时高并发、任务处理时间短，线程池的配置可设置如下：

```java
new ThreadPoolExecutor(
    16,                     // corePoolSize = 16（假设8核CPU × 2）
    32,                     // maximumPoolSize = 32（突发流量扩容）
    10, TimeUnit.SECONDS,   // 非核心线程空闲10秒回收
    new SynchronousQueue<>(), // 不缓存任务，直接扩容线程
    new AbortPolicy()       // 直接拒绝，避免系统过载
);
```

说明：

- 使用`SynchronousQueue`确保任务直达线程，避免队列延迟。
- 拒绝策略快速失败，前端返回“活动火爆”提示，结合降级策略（如缓存预热）。

场景二：后台数据处理服务，特点稳定流量、任务处理时间长（秒级）、允许一定延迟，线程池的配置可设置如下：

```java
new ThreadPoolExecutor(
    8,                      // corePoolSize = 8（8核CPU）
    8,                      // maximumPoolSize = 8（禁止扩容，避免资源耗尽）
    0, TimeUnit.SECONDS,    // 不回收线程
    new ArrayBlockingQueue<>(1000), // 有界队列，容量1000
    new CallerRunsPolicy()  // 队列满后由调用线程执行
);
```

说明：

- 固定线程数避免资源波动，队列缓冲任务，拒绝策略兜底。
- 配合监控告警（如队列使用率>80%触发扩容）。

场景三：微服务HTTP请求处理，特点IO密集型、依赖下游服务响应时间，线程池的配置可设置如下：

```java
new ThreadPoolExecutor(
    16,                     // corePoolSize = 16（8核 × 2）
    64,                     // maximumPoolSize = 64（应对慢下游）
    60, TimeUnit.SECONDS,   // 非核心线程空闲60秒回收
    new LinkedBlockingQueue<>(200), // 有界队列容量200
    new CustomRetryPolicy() // 自定义拒绝策略（重试或降级）
);
```

说明：

- 根据下游RT（响应时间）调整线程数，队列防止瞬时峰值。
- 自定义拒绝策略将任务暂存Redis，异步重试。

### **核心线程数设置为0可不可以？**

可以，当核心线程数为0的时候，会创建一个非核心线程进行执行。

### 线程池种类有哪些？

- ScheduledThreadPool：可以设置定期的执行任务，它支持定时或周期性执行任务，比如每隔 10 秒钟执行一次任务，我通过这个实现类设置定期执行任务的策略。
- FixedThreadPool：它的核心线程数和最大线程数是一样的，所以可以把它看作是固定线程数的线程池，它的特点是线程池中的线程数除了初始阶段需要从 0 开始增加外，之后的线程数量就是固定的，就算任务数超过线程数，线程池也不会再创建更多的线程来处理任务，而是会把超出线程处理能力的任务放到任务队列中进行等待。而且就算任务队列满了，到了本该继续增加线程数的时候，由于它的最大线程数和核心线程数是一样的，所以也无法再增加新的线程了。
- CachedThreadPool：可以称作可缓存线程池，它的特点在于线程数是几乎可以无限增加的（实际最大可以达到 Integer.MAX_VALUE，为 2^31-1，这个数非常大，所以基本不可能达到），而当线程闲置时还可以对线程进行回收。也就是说该线程池的线程数量不是固定不变的，当然它也有一个用于存储提交任务的队列，但这个队列是 SynchronousQueue，队列的容量为0，实际不存储任何任务，它只负责对任务进行中转和传递，所以效率比较高。
- SingleThreadExecutor：它会使用唯一的线程去执行任务，原理和 FixedThreadPool 是一样的，只不过这里线程只有一个，如果线程在执行任务的过程中发生异常，线程池也会重新创建一个线程来执行后续的任务。这种线程池由于只有一个线程，所以非常适合用于所有任务都需要按被提交的顺序依次执行的场景，而前几种线程池不一定能够保障任务的执行顺序等于被提交的顺序，因为它们是多线程并行执行的。
- SingleThreadScheduledExecutor：它实际和 ScheduledThreadPool 线程池非常相似，它只是 ScheduledThreadPool 的一个特例，内部只有一个线程。

### 线程池一般是怎么用的？

1. **使用 Executors 工厂类（快速创建）**

- 不建议使用 Executors 提供的newFixedThreadPool 和 newCachedThreadPool
- **固定大小线程池**：适用于负载较重的服务器
- **缓存线程池**：适用于大量短期异步任务
- **单线程线程池**：保证任务顺序执行
- **定时线程池**：支持定时和周期性任务

2. **使用 ThreadPoolExecutor 构造函数（推荐方式）**

- 提供完整的7个参数控制
- 可自定义线程工厂、拒绝策略
- 避免使用无界队列导致内存溢出

3. **在 Spring/Spring Boot 中使用**

- 通过配置类定义 ThreadPoolTaskExecutor
- 使用 @Async 注解实现异步方法
- 支持配置文件参数化

### 线程池和三个线程同时并发比有什么优势？

假设业务中需要处理大量并发任务，直接创建三个线程（或每次任务来了新建线程）存在明显局限，而线程池的优势主要体现在：

- **资源复用，降低开销**：线程创建 / 销毁需要内核态操作（如系统调用），开销较大。线程池会复用核心线程，避免频繁创建线程，尤其在任务量大时，能显著减少资源消耗。而三个固定线程若任务超过负载，要么排队等待（效率低），要么需要临时新建线程（开销高）。
- **控制并发强度，避免资源耗尽**：线程池通过最大线程数和队列限制并发数，防止线程无限制创建（比如瞬间 1000 个任务直接创建 1000 个线程，可能导致 CPU / 内存耗尽）。而三个线程若面对突发大量任务，要么处理不过来（任务堆积），要么手动扩容线程（难以控制）。
- **任务管理更灵活**：线程池支持任务排队、优先级调度、拒绝策略等，能应对任务峰值（如秒杀场景的突发请求）。而三个线程的并发方式，缺乏这些机制，任务处理逻辑会和业务代码耦合（如手动写队列、处理超时）。

### 线程池用了哪些设计模式？

线程池的实现中运用了多种设计模式，这些模式共同支撑了其高效的线程管理和任务调度能力，主要包括：

- **工厂模式**，体现在线程池的创建过程中。Java 中`Executors`类提供的`newFixedThreadPool`、`newCachedThreadPool`等静态方法，本质上是工厂方法，它们封装了`ThreadPoolExecutor`复杂的参数配置，根据不同场景返回预配置的线程池实例，简化了用户创建线程池的操作。用户无需关心线程池内部参数的细节，只需根据需求选择对应的工厂方法即可。

- **享元模式**，这是线程池的核心设计思想之一。线程池通过复用已创建的线程（尤其是核心线程）来执行多个任务，避免了频繁创建和销毁线程带来的资源消耗。线程作为 “共享资源”，在完成一个任务后不会被销毁，而是回到线程池等待新的任务，这种对线程资源的共享复用，正是享元模式的典型应用，有效提高了系统的资源利用率。

- **生产者 - 消费者模式**，体现在任务的提交与执行流程中。用户通过`execute`或`submit`方法提交任务（生产者），任务被放入阻塞队列中；线程池中的工作线程（消费者）不断从队列中取出任务并执行。阻塞队列作为缓冲区，平衡了生产者和消费者的处理速度，避免了任务提交过快导致的线程资源不足，或线程空闲时的资源浪费，实现了任务的异步处理和解耦。

- 隐式用到了**模板方法模式**。`ThreadPoolExecutor`的`execute`方法定义了任务执行的整体流程框架：先尝试添加任务到核心线程，失败则加入队列，再失败则创建非核心线程，最后执行拒绝策略。这个流程是固定的模板，而具体的任务执行、线程创建等细节则通过重写`beforeExecute`、`afterExecute`等钩子方法进行扩展，用户可以在不改变核心流程的前提下自定义任务执行前后的操作。

### 线程池中shutdown ()，shutdownNow()这两个方法有什么作用？

- shutdown使用了以后会置状态为SHUTDOWN，正在执行的任务会继续执行下去，没有被执行的则中断。此时，则不能再往线程池中添加任何任务，否则将会抛出 RejectedExecutionException 异常
-  shutdownNow 为STOP，并试图停止所有正在执行的线程，会返回那些未执行的任务，不再处理还在池队列中等待的任务。 它试图终止线程的方法是通过调用 Thread.interrupt() 方法来实现的，任务能不能被中断取决于它自己有没有响应中断信号。

### 提交给线程池中的任务可以被撤回吗？

可以，当向线程池提交任务时，会得到一个`Future`对象。这个`Future`对象提供了几种方法来管理任务的执行，包括取消任务。

取消任务的主要方法是`Future`接口中的`cancel(boolean mayInterruptIfRunning)`方法。这个方法尝试取消执行的任务。参数`mayInterruptIfRunning`指示是否允许中断正在执行的任务。如果设置为`true`，则表示如果任务已经开始执行，那么允许中断任务；如果设置为`false`，任务已经开始执行则不会被中断。

### 多线程打印奇偶数，怎么控制打印的顺序

可以利用wait()和notify()来控制线程的执行顺序。

```java
public class PrintOddEven {
    private static final Object lock = new Object();
    private static int count = 1;
    private static final int MAX_COUNT = 10;

    public static void main(String[] args) {
        Runnable printOdd = () -> {
            synchronized (lock) {
                while (count <= MAX_COUNT) {
                    if (count % 2 != 0) {
                        System.out.println(Thread.currentThread().getName() + ": " + count++);
                        lock.notify();
                    } else {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                }
            }
        };

        Runnable printEven = () -> {
            synchronized (lock) {
                while (count <= MAX_COUNT) {
                    if (count % 2 == 0) {
                        System.out.println(Thread.currentThread().getName() + ": " + count++);
                        lock.notify();
                    } else {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                }
            }
        };

        Thread oddThread = new Thread(printOdd, "OddThread");
        Thread evenThread = new Thread(printEven, "EvenThread");

        oddThread.start();
        evenThread.start();
    }
}
```

### 单例模型既然已经用了synchronized，为什么还要在加volatile？

`volatile` 确保了对象引用的可见性和创建过程的有序性，避免了由于指令重排序而导致的错误。

`instance = new Singleton();` 这行代码并不是一个原子操作，它实际上可以分解为以下几个步骤：

- 分配内存空间。
- 实例化对象。
- 将对象引用赋值给 `instance`。

由于 Java 内存模型允许编译器和处理器对指令进行重排序，在没有 `volatile` 的情况下，可能会出现重排序，例如先将对象引用赋值给 `instance`，但对象的实例化操作尚未完成。

这样，其他线程在检查 `instance == null` 时，会认为单例已经创建，从而得到一个未完全初始化的对象，导致错误。

`volatile` 可以保证变量的可见性和禁止指令重排序。它确保对 `instance` 的修改对所有线程都是可见的，并且保证了上述三个步骤按顺序执行，避免了在单例创建过程中因指令重排序而导致的问题。
